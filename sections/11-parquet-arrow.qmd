---
title: "Data Futures: Parquet and Arrow"
---

## Learning Objectives

- The difference between column major and row major data
- Speed advantages to columnnar data storage
- How `arrow` enables faster processing

## Introduction

- open, seek, read, write, close - ways to access data
- difference between parquet and arrow
    - how paging and memory management works, blocks are organized by pages
    - on disk and in memory representation are the same 
- column (parquet) vs row (csv) data example
- why column can give faster read speeds
- how arrow interacts with columnar data formats (like parquet)

## Row major vs column major

The difference between row major and column major is the ordering of the objects. 

Take the array:
```
a11 a12 a13

a21 a22 a23
```

This array in a row-major order would be read in as:

`a11, a12, a13, a21, a22, a23`

You could also read it in column-major order as:

`a11, a21, a12, a22, a13, a33`

By default, C and SAS use row major order for arrays, and column major is used by Fortran, MATLAB, R, and Julia.

Python uses neither, instead representing arrays as lists of lists, though `numpy` uses row-major order.

### File formats

The same concept can be applied to file formats as the example with arrays above. In row-major file formats, the values (bytes) of each record are read sequentially.

Name | Location | Age
-----|----------|----
John | Washington| 40
Mariah | Texas | 21
Allison | Oregon | 57

In the above row major example, data are read in the order:
`John, Washingon, 40, [new line], Mariah, Texas, 21`.

This means that getting a subset of all columns would be easy; you can specify to read in only the first X rows. However, if we are only interested in Name and Location, we would still have to read in all of the rows before discarding the Age column.

If these data were organized in a column major format, they might look like this:

```
Name: John, Mariah, Allison
Location: Washington, Texas, Oregon
Age: 40, 21, 57
```

And the read order would first be the names, then the locations, then the age. This means that selecting all values from a set of columns is quite easy (all of the Names and Ages, or all Names and Locations), but reading in only the first few records from each column would require reading in the entire dataset. Another advantage to column major formats is that compression is more efficient since compression can be done across each column, where the data type is uniform, as opposed to across rows with many data types.

## Parquet

Parquet is an open-source file format that stores data in a column-major format. The format contains several key components:

- row group
- column
- page
- footer

![](../images/parquet-schematic.png)

Row groups are blocks of data over a set number of rows that contain data from the same columns. Within each row group, data are organized in column-major format, and within each column are pages that are typically 1MB. The footer of the file contains metaata like the schema, encodings, unique values in each column, etc.

The parquet format has many tricks to to increase storage efficiency, and is increasingly being used to handle large datasets.

## Arrow

So far, we have discussed the difference between organizing information in row-major and column-major format, how that applies to arrays, and how it applies to data storage on disk using Parquet.

Arrow is a language-agnostic specification that enables representation of column-major information **in memory**. The Arrow project provides implementation of this specification in a number of languages, including Python.

Let's say that you have utilized the Parquet data format for more efficient storage of your data on disk. At some point, you'll need to read that data into memory in order to do analysis on it. Arrow enables data transfer between the on disk Parquet files and in-memory Python computations, via the `PyArrow` library.

`PyArrow` is great, but relatively low level. It supports basic group by and aggregate functions, as well as table and dataset joins, but it does not support the full operations that `pandas` does.

## Example

- show a read write example and benchmark maybe

