---
title: "Parallelization with Dask"
---
## Introduction
Dask is a library for parallel computing in Python. 
It can scale up code to use the full capacity of your personal computer or to use a cloud cluster. 
By mirroring APIs of other commonly used Python libraries such as Pandas, NumPy, and Scikit-learn, Dask provides a familiar interface that makes it easier to parallelize your code. 
In this lesson, we will get acquainted with some of Dask's most commonly used objects and Dask's way of distributing and evaluating computations. 

![ ](../images/dask_logo.png)

## Objectives

- Learn basics of `dask.arrays` and `dask.dataframes`:
    - Load data and specifying chunk sizes
    - Understand delayed computations and "lazy" evaluation
    - https://saturncloud.io/blog/a-data-scientist-s-guide-to-lazy-evaluation-with-dask/
    - Interpret a task graph

- Integrate `xarray` with Dask:
    - https://docs.xarray.dev/en/stable/user-guide/dask.html
    
- Become familiar with Dask's distributed scheduler:
    - What are the client, scheduler, workers, and cluster
    - https://www.datarevenue.com/en-blog/understanding-dask-architecture-client-scheduler-workers

    https://tutorial.dask.org/04_distributed.html
    - Obtain information about computations via the Dask dashboard
    - https://www.youtube.com/watch?v=N_GqzcuGLCY
    - https://medium.com/@kartikbhanot/dask-scheduler-dashboard-understanding-resource-and-task-allocation-in-local-machines-bc5aa60eca6e

- Share best practices and resources for a deeper dive
    - https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask
    - https://coiled.io/blog/common-dask-mistakes/

## Possible computing examples:
https://docs.dask.org/en/latest/10-minutes-to-dask.html 

https://tutorial.dask.org/00_overview.html






Dask provides high-level Array, Bag, and DataFrame collections that mimic NumPy, lists, and pandas but can operate in parallel on datasets that don’t fit into memory.

It is important to remember that, while APIs may be similar, some differences do exist. Additionally, the performance of some algorithms may differ from their in-memory counterparts due to the advantages and disadvantages of parallel programming.  


## Dask Data Frames

When we analyze tabular data, we usually start our analysis by loading it into memory as a Pandas DataFrame. 
But, what if this data does not fit in memory? 
Or maybe our analyzes crash because we run out of memory? 
These scenarios are typical entry points into parallel computing. 
In such cases, Dask’s scalable alternative to a Pandas DataFrame is the Dask Dataframe. 
A `dask.DataFrame` is made up of many `pd.DataFrames`, each containing a subset of rows of the original dataset.
We call each of these pandas pieces a *partition* of the `dask.DataFrame`.



![ Dask Array design ([dask documentation](https://docs.dask.org/en/latest/dataframe.html))](../images/dask_dataframe.png)

```{python}
## THIS IS AN EXAMPLE OF LOADING A MASSIVE FILE OR CREATING A REALLY BIG DATAFRAME

```


The application programming interface (API) of a `dask.DataFrame` is a subset of the `pd.DataFrame` API.
So if you are familiar with pandas, many of the core `pd.DataFrame` methods directly translate to `dask.DataFrames`. 



A major difference between both objects is that `dask.DataFrames` are *lazy*, meaning that they do not evaluate until we explicitly ask for a result using the `compute` method.
This is the case with most Dask workloads.

```{python}
## THIS IS AN EXAMPLE OF LAZY COMPUTATION

```


*This means that your framework will queue up sets of transformations or calculations so that they are ready to run later, in parallel. This is a concept you’ll find in lots of frameworks for parallel computing, including Dask. Your framework won’t evaluate the requested computations until explicitly told to. This differs from “eager” evaluation functions, which compute instantly upon being called.*

https://saturncloud.io/blog/a-data-scientist-s-guide-to-lazy-evaluation-with-dask/ 
Lead into task graphs. 
```{python}
### THIS IS AN EXAMPLE OF TASK GRAPH
```




## Dask Arrays
If you want scalable NumPy arrays, then start with Dask array


![ Dask Array design ([dask documentation](https://docs.dask.org/en/latest/array.html))](../images/dask_array.png)

## Best Practices

It is important to remember that, while APIs may be similar, some differences do exist. Additionally, the performance of some algorithms may differ from their in-memory counterparts due to the advantages and disadvantages of parallel programming. Some thought and attention is still required when using Dask.
https://docs.dask.org/en/latest/user-interfaces.html

:::{.callout-warning}
For data that fits into RAM, Pandas can often be faster and easier to use than Dask DataFrame. 
While “Big Data” tools can be exciting, they are almost always worse than normal data tools while those remain appropriate.
https://docs.dask.org/en/stable/dataframe-best-practices.html
:::

## TODO

- Find dataset(s) to use:
    - https://arcticdata.io/catalog/view/doi%3A10.18739%2FA24B2X59C
        "Understory micrometorology across a larch forest density gradient in northeastern Siberia 2014-2020"
        ~50MB, has a few different axes to filter on
    - https://arcticdata.io/catalog/view/doi%3A10.18739%2FA28W38388
        "River and lake ice phenology data for Alaska and Northwest Canada from 1882 to 2021"
    - Also check out candidats in the xarray lesson TODO section


### Notes

- https://www.dask.org/
- https://docs.xarray.dev/en/stable/user-guide/dask.html#dask
- https://stephanhoyer.com/2015/06/11/xray-dask-out-of-core-labeled-arrays/
- https://examples.dask.org/xarray.html
- Good example to base exercise on: https://examples.dask.org/applications/image-processing.html

- Split-apply-combine
- Dask stuff
    - Lazy eval (compute())
        - Grouping compute() calls versus calling compute() multiple times
    - Dask Array
    - Dask DataFrame
    - Skip or just mention Bag, Delayed, Futures? Not sure yet.
    - visualize()
    - Choosing how many chunks to divide work into
    - Task overhead
    - Distributed dask?
        - Persist
> Dask is convenient on a laptop. It installs trivially with conda or pip and extends the size of convenient datasets from “fits in memory” to “fits on disk”.

-- From https://docs.dask.org/en/stable/