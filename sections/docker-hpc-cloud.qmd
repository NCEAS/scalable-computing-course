---
title: "Containers in HPC and Cloud"
---

## Learning Objectives

- Discuss containers in high performace computing environments
- Explore orchestration formats
- Learn how to use docker compose to build a workflow
- Explore a real world Kubernetes service

## Container orchestration systems

Container orchestration is the process of linking multiple containers into an integrated application. These applications can represent a computational workflow, a backend service or data store, a frontend application, or some combination of these and others.  For example, a simple application might consist of a backend database system in a container, which is accessed by containerized data processing code, and which is served by a containerized web application.

![](../images/docker-compose-workflow.png)

All of these types of integrated systems can be built by orchestrating the deployment of multiple containers, whether creating scientific applications for running big data jobs on high performance computers or building and deploying scientific web applications and services.

Let's explore a few container orchestration systems.

### docker compose

[Docker Compose](https://docs.docker.com/compose/) is "a tool for defining and running multi-container applications". This is the essence of orchestration. With just the `compose` application, you can link multiple containers into an integrated application to run it on demand. This is particularly useful to quickly bring up a backend and frontend application, say one that uses a database (like `postgresql`) or a caching server (like `redis`) and combine it with a web-based frontend.

Creating a docker compose application is done by editing a `compose.yaml` configuration document that describes each of the containers to be run in the system, and how they are linked together. In the simplest "Hello world" case, you simply create the service you want to run by identifying the image to be executed. For example, given this `compose.yaml`, file:

```yaml
services:
  hello_world:
    image: hello-world
```

Run it with `docker-compose up`, and it produces the familiar hello world output.

```bash
$ docker-compose up
[+] Running 2/0
 ✔ Network 15-containers_default          Created                                                                                                            0.0s
 ✔ Container 15-containers-hello_world-1  Created                                                                                                            0.0s
Attaching to hello_world-1
hello_world-1  |
hello_world-1  | Hello from Docker!
hello_world-1  | This message shows that your installation appears to be working correctly.
hello_world-1  |
hello_world-1  | To generate this message, Docker took the following steps:
hello_world-1  |  1. The Docker client contacted the Docker daemon.
hello_world-1  |  2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
hello_world-1  |     (arm64v8)
hello_world-1  |  3. The Docker daemon created a new container from that image which runs the
hello_world-1  |     executable that produces the output you are currently reading.
hello_world-1  |  4. The Docker daemon streamed that output to the Docker client, which sent it
hello_world-1  |     to your terminal.
hello_world-1  |
hello_world-1  | To try something more ambitious, you can run an Ubuntu container with:
hello_world-1  |  $ docker run -it ubuntu bash
hello_world-1  |
hello_world-1  | Share images, automate workflows, and more with a free Docker ID:
hello_world-1  |  https://hub.docker.com/
hello_world-1  |
hello_world-1  | For more examples and ideas, visit:
hello_world-1  |  https://docs.docker.com/get-started/
hello_world-1  |
hello_world-1 exited with code 0
```

The big difference is that you can add multiple services that run containers in a compose file, and they will be launched and can communicate with one another. compose also handles some housekeeping for you, in that it cleans up containers when the application shuts down.

Let's build a simple web application with docker compose. First, create a directory to hold our website files, and initialize it with a simple web page.

```bash
$ mkdir -p ~/adc-course/web
$ echo '<h1>Scalable Computing Course</h1>' > ~/adc-course/web/index.html
```

Next, create the `compose.yaml`, and use the stock `nginx` image from DockerHub to serve the file. We'll throw the `hello-world` container in as well just to show two services can be run from the same application:

```yaml
services:
  web:
    image: nginx
    ports:
      - 8000:80
    volumes:
      - ~/adc-course/web:/usr/share/nginx/html
  hello_world:
    image: hello-world
```

Finally, run it with `docker-compose up --detach`:

```bash
$ docker-compose up --detach
[+] Running 8/8
 ✔ web 7 layers [⣿⣿⣿⣿⣿⣿⣿]      0B/0B      Pulled                                                                                                           304.3s
   ✔ 59f5764b1f6d Pull complete                                                                                                                            251.0s
   ✔ f7bd43626fa7 Pull complete                                                                                                                            288.1s
   ✔ 2df415630b2f Pull complete                                                                                                                              5.3s
   ✔ 059f9f6918db Pull complete                                                                                                                             10.5s
   ✔ df91ff398a83 Pull complete                                                                                                                             15.9s
   ✔ e75b854d63f1 Pull complete                                                                                                                             21.4s
   ✔ 4b88df8a13cd Pull complete                                                                                                                             26.5s
[+] Running 2/2
 ✔ Container 15-containers-web-1          Started                                                                                                            0.1s
 ✔ Container 15-containers-hello_world-1  Started                                                                                                            0.0s
 ```

Your website should now be live on your local machine at [https://localhost:8000](https://localhost:8000/). And while it is running, you can now see the executing containers on your host. Port 8000 on the local host is mapped to port 80 in the nginx container.

:::{.column-page-right}
```bash
$ docker ps
CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                                   NAMES
5d634a37ba09   nginx     "/docker-entrypoint.…"   5 seconds ago   Up 5 seconds   0.0.0.0:8000->80/tcp, :::8000->80/tcp   15-containers-web-1
```
:::

Note that only the `nginx` container is running. The `hello-world` container started up, printed its content, and immediately exited. Whereas the `nginx` image was designed to run the web server continuously until told to shut down. You can shut down the containers with `docker-compose down`:

:::{.column-page-right}
```bash
$ docker-compose down
[+] Running 3/3
 ✔ Container 15-containers-web-1          Removed                                                                                                            0.5s
 ✔ Container 15-containers-hello_world-1  Removed                                                                                                            0.0s
 ✔ Network 15-containers_default          Removed                                                                                                            0.1s
 ```
:::

::: {.callout-note}
## Challenge exercise

Using the `adccourse:1.0` image that we created earlier, write a docker-compose application that:

- runs the `max-discharge.py` script to generate the `max-discharge.png` image showing discharge data
- copies the png file to the `web` directory that you just set up
- modifies the `index.html` file to display the plot on the web page
- starts up your web application with `docker-compose up --detach`

Hint: You will likely want to use the [`depends_on`](https://docs.docker.com/compose/compose-file/05-services/#depends_on) keyword and the [`command`](https://docs.docker.com/compose/compose-file/05-services/#command) keyword in your `compose.yaml` service description to modify the command that is run by the `adccourse:1.0` container.
:::

:::{.callout-tip collapse="true"}
## Solution

First, modify our base `index.html` to display the dynamically generated image:

```bash
echo '<img src="max-discharge.png">' >> ~/adc-course/web/index.html
```

Second, add `adccourse` to the `compose.yaml`, and change the `command` to also copy the produced png file into the web directory.

```yaml
services:
  web:
    image: nginx
    ports:
      - 8000:80
    volumes:
      - ~/adc-course/web:/usr/share/nginx/html
    depends_on:
      - adccourse
  adccourse:
    image: adccourse:1.0
    volumes:
      - ~/adc-course:/var/data
    command: [ "bash", "-i", "-c", "workon scomp && python /var/data/scripts/max-discharge.py && cp /var/data/output/max-discharge.png /var/data/web/max-discharge.png" ]
```
Note how we used `depends_on` to ensure the `adccourse` service produces the png file before the `nginx` service is started. Our web page now inlcudes the dynamically generated plot:

![](../images/docker-compose-web-plot.png)

:::

### Kubernetes

::: {layout="[[70,-10,20]]"}

[Kubernetes](https://kubernetes.io) is fundamentally an orchestration system for executing containerized applications on the nodes of distributed computing clusters. Kubernetes creates fault tolerance, high availability, and scalability for applications deployed on a cluster.

![](../images/k8s-logo.png)

:::

It does so by creating a high availability control plane that manages all aspects of the definition, creation, and execution of containers on nodes of the cluster. Thus, if a container running on one node of a cluster fails, or loses network connectivity, the Kubernetes control plane brings the container back up on another node in the cluster. 

While the [core concepts in Kubernetes](https://kubernetes.io/docs/concepts/) are extensive and have been reviewed in some [more comprehensive tutorials](https://www.digitalocean.com/community/tutorials/an-introduction-to-kubernetes), a quick overview of the core concepts will show the parallels between Kubernetes and Docker Compose.

![](../images/k8s-arch.png)

Similarly to compose, Kubernetes executes application containers based on OCI images, but these are bundled into Pods. A Pod in Kubernetes is the smallest unit of a workload that can be deployed on a node, and it consists of one or more containers that will be executed within the Pod. Containers within a Pod are tichtly linked and share network and other resources, making it easy for them to coordinate. Pods are deployed onto one or more Nodes in a Kubernetes cluster, where a Node corresponds to a physical or virtual server that is managed by Kubernetes. The Kubernetes control plane includes a scheduler that determines how to schedule the execution of Pods onto Nodes within a deployment, how to ensure that unhealthy Pods get terminated and restarted on other Nodes, and when the number of Pods needs to be increased or decreased to scale an application.

Like other container systems, Kubernetes is configured through a set of YAML configuration files. While that is too complex for this bried introduction we can show how Kubernetes can be used by other orchestration frameworks.

### Parsl on Kubernetes

::: {layout="[[70,30]]"}

Parsl is all about the beef...

![](../images/parsl-logo.png)

:::

Remember the basic layout of a parsl app:

```python
# Define the square task.
import parsl
@python_app
def square(x):
    return x * x

# Launch four parallel square tasks.
futures = [square(i) for i in range(4)]

# Retrieve results.
squares = [future.result() for future in futures]
print(squares)
# -> [0, 1, 4, 9]
```


### Ray.io

::: {layout="[[60,40]]"}

[Ray](https://ray.io) is structured so similarly to Parsl...

![](../images/ray-logo.png)

:::

![](../images/ray-components.png)

[Ray Core](https://docs.ray.io/en/latest/ray-core/walkthrough.html) is fairly analogous to Parsl, and provides the core functionality for distributed execution. 

```python
# Define the square task.
@ray.remote
def square(x):
    return x * x

# Launch four parallel square tasks.
futures = [square.remote(i) for i in range(4)]

# Retrieve results.
print(ray.get(futures))
# -> [0, 1, 4, 9]
```

### Kubeflow

[Kubeflow](https://www.kubeflow.org/)
![](../images/kubeflow-logo.png)

```python
# Kubeflow pipeline example
from kfp import dsl

@dsl.component
def say_hello(name: str) -> str:
    hello_text = f'Hello, {name}!'
    print(hello_text)
    return hello_text

@dsl.pipeline
def hello_pipeline(recipient: str) -> str:
    hello_task = say_hello(name=recipient)
    return hello_task.output
```

## How weird is the weather?

Big data are hard to visualize, and sometimes we need to come up with clever ways to pack a lot of data into a small space. This is exactly what the **How weird is the weather?** project did ([hwitw github](https://github.com/howweirdistheweather/weather_app)), by summarizing the [ERA5 climate reanalysis data](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) and providing a means to visualize over 70 years of climate data interactively. This project, developed by Brentwood Higman, John McInnes, and Katmai McKittrick, shows where climate extremes have occurred over the ERA5 dataset. First, pick any location on the globe via the work-in-progress [sandcastle demo](https://sandcastle.cesium.com/#c=tVbbcts2EP0VVNNp6YlK2pn2RbLcxqodeyKPMpEvD2HGgcmViDEEcABQspPo37sASAq6uE0e+qIRsddzdrHYJCETMKQqiSmADEGzak4WDJag4lRkUmhTf5IBEbCsVeJbdxalncx9D6UwlAlQaadLvqaCEA0cMsOkuBQ5y6iRqkemlGvoWikTU3kqn9ZHq4N+E05nIACj1Vm4TxSmIknIKdVAbj6MyFQqciGX5A6YysmlJteY/h1QRLFOvFLcGQxI2imMKXUvSYolM8vfcljEVGF+WU4NjZlMtKH4lTCRw1NcmDn/M+00UYcKHUPI0FxW6BcWIAwpqMg5Iq+D1p+bdE0yBSAmJc3gzBpdeKXIgYszKhZUH+wJh6rMPONfasiScY60qgUQqp2U0wfgXpgzXXL63JybhEvR8uD1WkadUwY6pnkeuWI5hZ4vHJaukMuwWP7klGaPMyUrkfeIUVUjmmLle8jv0e/lE9IipLYgsQ28uJCKfbHNwceKzZjoNYxcbAni0dn5dW20AIW12DG53TiOr8fva/2SPQEfT6caMJWA9SFVBv9R8To6+qNLDg+c/qppN0+2FDYcoSRDbTlTtCxYRjIpsa+MxPMpes9JDhmbUyyAUUzMkNppJVx/21acUzMMrCNnzQRW8cCTqsBUSjR5XWGbxkb+DTPsCh1q4+m5DRe9tgmu6hzfMuyZuufWyrpLZnh1g4LbvqB1hkGCqDWiZiTFxEmirKGlTo5NSfRTcOiT7VuR758NZgYhu81pPFVy3tIdRAi8YIIzZqocfBroaB9zodPWYsMN3tMf81IbeCd1JT5uZdPd8vspoP/cBXiJaDeKrOzi7vL6zg6n3ebw9KMfpxNx9/lGKfpcl8BD+8+kEG1gG+L5jOeDn79u6q9+QYf2dNPt6vOPg3MT4l+Ajaz8fwGGIXpkB1maVoeHp4ddgjZOvAWxlodIb8q8Gat+IOJLUGwArzHjbCal1MzhZIbgr9WacfkAIQWVc+iR6xrX9t3yvLXeBmuF/lrsf+2QRQU7W3dkBp4MynyUANMFy2F/fQqU+NQ2MtkI5UZ84O0dAO4BCgc9kdParb9xAT0YhINxkvc1rPYqfvzUjNWJjWA9tNBrj36KhZSSZcE4ING/apQufIj6FY1xpF+KsjJvHKqohRehJszxJdvos5bc9WOX0TkoGpcsezzjnJVasjzyz0bjAh/EvIHSPHjuXfYVh8bMisJJhNA8co3hXh6y/XbGrg0Omrc2KFPfnwTTd+Xrtofotac+8ZfY8ZlxhOnXkjicmOi/MfVB0s5LyxOhJsUadsir/Vc8wOBqTTauQRAqvAu2x7ov7ULXzyXEV+Obydn91fj2rH2ZP0DOFO6Q9hX2s1W2j6DF+T1dEr5we4j89o3sOY45iJkp2hptV6Te8+wiufUI7cz5bddh++B2iobNjvoqdOi0lriLymUsSxARanWxaPcPnIrHtPMdhNp16n44uhy+s8qdbudYm2cOJx4SIX+xeSmVyyKK48TAHPdHLFfyUGWPYOJM66Yjj5PQ9DhnC8LywZ7VH+tCtUbJtOJ8wr7gGnhynKD+jimXFJeY2RhXL9xarVpxdDLyh3EcHyf4ud/SSMkfqNry/A8):

![](../images/hwitw-globe.png)

Next, configure the application to show the climate variables of interest. Here, I show the extremes of the average daily temperature where I live in Juneau, AK. The cold temperatures from the 1950s and 1960s haven't been seen in decades, and now the hottest temperatures are constant throughout the summer.

![](../images/hwitw-jnu-temp.png)

### Kubernetes deployment

Let's examine the Kubernetes deployment. There are three major working in concert. Two CronJobs are configured, one to download data from Copernicus, and the other to transform that data into weekly summaries in a compact HDF format.

![](../images/hwitw-arch.png)

Each of these CronJobs spawns a series of Pods that run the containers with the `cdstool` and `tiletool` processes. Once the data has been output by tiletool, it can be accessed on the web. Web client sessions are handled by the Ingress, and dispatched to the HWITW Service, which in turn is implemented by a Pod running the `nginx` web server with the hwitw frontend HTML and Javascript code.

We can inspect these components more carefully in Kubernetes using the `kubectl` commandline utility.

:::{.column-page-right}

```bash
$ kubectl get services
NAME            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
service/hwitw   ClusterIP   10.109.0.227   <none>        5000/TCP   407d
```

That service is deployed in a pod running the `hwitw` container as a web service. In the pod listing below, you can also see that there are pods that have completed running for periodic cronjobs for `cdstool`, which downloads data from the Copernicus Data Service, and `tiletool`, which processes that data into weekly summaries and reorganizes it by time region in a large HDF5 file.

```bash
$ kubectl get pods
NAME                                   READY   STATUS      RESTARTS   AGE
pod/hwitw-67ccd577-rltrp               1/1     Running     0          160d
pod/hwitw-cdstool-28478538--1-99m2n    0/1     Completed   0          34d
pod/hwitw-cdstool-28508778--1-l5twt    0/1     Completed   0          13d
pod/hwitw-cdstool-28518858--1-xzpkn    0/1     Completed   0          6d10h
pod/hwitw-tiletool-28478543--1-28d2n   0/1     Completed   0          34d
pod/hwitw-tiletool-28508783--1-ldzdm   0/1     Completed   0          13d
pod/hwitw-tiletool-28518863--1-js8mj   0/1     Completed   0          6d10h
```

The CronJobs show the details of the schedule for these episodic processes, and the container implementation that was used for each run.

```bash
$ kubectl get cronjobs
NAME                           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/hwitw-cdstool    18 18 * * 5   False     0        6d10h           170d
cronjob.batch/hwitw-tiletool   23 18 * * 5   False     0        6d10h           170d

$ kubectl get jobs -o wide
NAME                      COMPLETIONS   DURATION   AGE     CONTAINERS          IMAGES
hwitw-cdstool-28478538    1/1           13s        34d     hwitw-cdstool-job   ghcr.io/nceas/hwitw:0.9.6
hwitw-cdstool-28508778    1/1           9s         13d     hwitw-cdstool-job   ghcr.io/nceas/hwitw:0.9.6
hwitw-cdstool-28518858    1/1           10s        6d11h   hwitw-cdstool-job   ghcr.io/nceas/hwitw:0.9.6
hwitw-tiletool-28478543   1/1           13s        34d     hwitw-cdstool-job   ghcr.io/nceas/hwitw:0.9.6
hwitw-tiletool-28508783   1/1           11s        13d     hwitw-cdstool-job   ghcr.io/nceas/hwitw:0.9.6
hwitw-tiletool-28518863   1/1           6s         6d10h   hwitw-cdstool-job   ghcr.io/nceas/hwitw:0.9.6
```
:::

Together, these Kubernetes resources, and a few others including an Ingress Controller to glue the application together, constitue a complete data access, data processing, and web visualization service for scientific data. The entire application can be deployed with a single command.

## Resources

- [Docker compose tutorial](https://www.baeldung.com/ops/docker-compose)
- [Kubernetes documentation](https://kubernetes.io/docs/concepts/)
- [Digital Ocean introduction to kubernetes](https://www.digitalocean.com/community/tutorials/an-introduction-to-kubernetes)